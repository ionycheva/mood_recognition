{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset Maker"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "1. Reading raw data\n",
    "2. Cleansing\n",
    "3. Lemmatize\n",
    "4. Vectorize data via TF-IDF method\n",
    "3. Save vectorizer and final data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-27T20:49:10.686583Z",
     "start_time": "2023-07-27T20:49:09.693884Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pymorphy3\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from joblib import dump\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def save_file(name: str, obj: list, path: str):\n",
    "    \"\"\" Write prepared data to files saving data structure \"\"\"\n",
    "    with open('{path}/{name}.pickle'.format(name=name, path=path), 'wb') as handle:\n",
    "        pickle.dump(obj, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T20:49:10.688518Z",
     "start_time": "2023-07-27T20:49:10.687083Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "special_characters = ['</p>', '\\xa0', '<br/>', '\\n', '-&gt;']\n",
    "\n",
    "stop_words = ['в', 'на', 'с', 'и', 'я', 'о', 'к', 'а', 'за', 'по',\n",
    "              'об', 'у', 'бы', 'от', 'ли', 'ул', 'что', 'со', 'из',\n",
    "              'для', 'про', 'г', 'до', 'то', 'быть', 'по', 'мочь',\n",
    "              'январь','февраль','март','апрель','май','июнь','июль',\n",
    "              'август','сентябрь','октябрь','ноябрь','декабрь','год',\n",
    "              'стать','это','когда','даже', 'янв', 'фев', 'апр', 'авг',\n",
    "              'сен', 'окт', 'ноя', 'дек', 'ые', 'ый', 'ым', 'ых', 'ая']\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T20:49:10.691217Z",
     "start_time": "2023-07-27T20:49:10.689734Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reading data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "''"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading data from files and writing it into variables\n",
    "\n",
    "f = open(\"data/reviews_positive.txt\", \"r\")\n",
    "positive_reviews = f.read().split('<p>')\n",
    "positive_reviews.pop(0)\n",
    "\n",
    "f = open(\"data/reviews_neutral.txt\", \"r\")\n",
    "neutral_reviews = f.read().split('<p>')\n",
    "neutral_reviews.pop(0)\n",
    "\n",
    "f = open(\"data/reviews_negative.txt\", \"r\")\n",
    "negative_reviews = f.read().split('<p>')\n",
    "negative_reviews.pop(0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T20:49:10.718823Z",
     "start_time": "2023-07-27T20:49:10.692417Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data processing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def cleansing(text: list) -> list:\n",
    "    \"\"\" Removes numbers, special characters\n",
    "        and Roman alphabet characters from raw data.\n",
    "        Converts all characters to lowercase \"\"\"\n",
    "    res = []\n",
    "    for i in range(len(text)):\n",
    "        res.append(text[i])\n",
    "        for sp_ch in special_characters:\n",
    "            res[i] = (text[i].replace(sp_ch,' '))\n",
    "        res[i] = res[i].lower()\n",
    "        res[i] = re.sub(r'[^\\w\\s]', ' ', res[i])\n",
    "        res[i] = re.sub(r'[^\\w\\s]+|[\\d]+', r' ',res[i]).strip()\n",
    "        res[i] = re.sub('[a-zA-Z\\s]+', ' ', res[i])\n",
    "        res[i] = re.sub(\" +\", \" \", res[i])\n",
    "\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T20:49:10.719057Z",
     "start_time": "2023-07-27T20:49:10.718690Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "morph = pymorphy3.MorphAnalyzer()\n",
    "\n",
    "def lemmatize(sentence: str) -> list:\n",
    "    \"\"\" Converts each word in a sentence to its initial form\"\"\"\n",
    "    words = sentence.split()  # Split sentence into words\n",
    "    res = list()\n",
    "    for word in words:\n",
    "        p = morph.parse(word)[0]\n",
    "        res.append(p.normal_form)\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T20:49:10.754072Z",
     "start_time": "2023-07-27T20:49:10.718977Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def delete_stop_words(sentence: list) -> list:\n",
    "    \"\"\" Removes stop-words from a sentence \"\"\"\n",
    "    res = list()\n",
    "    for word in sentence:\n",
    "        if word not in stop_words:\n",
    "            res.append(word)\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T20:49:10.755898Z",
     "start_time": "2023-07-27T20:49:10.754656Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def join(sentence: list) -> str:\n",
    "    \"\"\" Joins list sentence into a string \"\"\"\n",
    "    return ' '.join(sentence)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T20:49:10.757886Z",
     "start_time": "2023-07-27T20:49:10.756523Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def processing_pipeline(reviews):\n",
    "    \"\"\" Passes raw data through all processing methods \"\"\"\n",
    "    cleansed_reviews = cleansing(reviews)\n",
    "    lemmatized_reviews = list(map(lemmatize,cleansed_reviews))\n",
    "    clean_reviews = list(map(delete_stop_words,lemmatized_reviews))\n",
    "    final_reviews = list(map(join,clean_reviews))\n",
    "    return final_reviews"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T20:49:10.760193Z",
     "start_time": "2023-07-27T20:49:10.758826Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data preparation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "positive_data = processing_pipeline(positive_reviews)\n",
    "neutral_data = processing_pipeline(neutral_reviews)\n",
    "negative_data = processing_pipeline(negative_reviews)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T20:49:32.520670Z",
     "start_time": "2023-07-27T20:49:10.810200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Перешёл по ссылке друга оформил карту получил в ближайшем банке активно пользуюсь.в причине отказа оформления кэшбека пишут-вы не получили карту (просто недоумеваю).звонил на горячую линию ,обещали разобраться в течении 5 рабочих дней-прошло две недели.берут на измор,пока сам не отстанеш.</p>\\n'"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Raw data: \\n')\n",
    "negative_reviews[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T20:49:32.530957Z",
     "start_time": "2023-07-27T20:49:32.521390Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final data: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "'перейти ссылка друг оформить карта получить близкий банк активно пользоваться причина отказ оформление кэшбек писать вы не получить карта просто недоумевать звонить горячий линия обещать разобраться течение рабочий день пройти два неделя брать измор пока сам не отстанеш'"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Final data: \\n')\n",
    "negative_data[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T20:49:32.532003Z",
     "start_time": "2023-07-27T20:49:32.530797Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data vectorization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "['vectorizer.joblib']"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making final corpus\n",
    "data = np.concatenate((positive_data,neutral_data))\n",
    "data = np.concatenate((data,negative_data))\n",
    "\n",
    "# Making TF-IDF matrix from the resulting corpus\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(data)\n",
    "\n",
    "# Saving vectorizer\n",
    "dump(vectorizer, 'vectorizer.joblib')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T17:05:38.195112Z",
     "start_time": "2023-07-26T17:05:37.724104Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save final data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "save_file('data_positive', positive_data, 'prepared_data')\n",
    "save_file('data_neutral', neutral_data, 'prepared_data')\n",
    "save_file('data_negative', negative_data, 'prepared_data')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T17:05:38.201821Z",
     "start_time": "2023-07-26T17:05:38.195367Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T17:05:38.203701Z",
     "start_time": "2023-07-26T17:05:38.202104Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
